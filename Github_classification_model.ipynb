{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jogong2718/COVID-19-Radiography-Models/blob/main/Github_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFPMuzuxlP0g"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import imageio as iio\n",
        "import cv2 as cv\n",
        "import pickle\n",
        "from natsort import natsorted\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XwgoKQeliIc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENPwnNdglnZo"
      },
      "outputs": [],
      "source": [
        "os.chdir('your data link')\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StnTjRcFg232"
      },
      "outputs": [],
      "source": [
        "with open('test_everything_final_2.pkl', 'rb') as handle:\n",
        "    test_everything = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKVf7-clg-Ej"
      },
      "outputs": [],
      "source": [
        "with open('train_everything_final_2.pkl', 'rb') as handle:\n",
        "    train_everything = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMCnxrdNlxHG"
      },
      "outputs": [],
      "source": [
        "test_data = test_everything[0]\n",
        "train_data = train_everything[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YXMG6EDl7TV"
      },
      "outputs": [],
      "source": [
        "train_data = train_data/255.\n",
        "test_data = test_data/255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UvBxyomWmsY"
      },
      "outputs": [],
      "source": [
        "train_data.shape\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXdJR2oCEpbf"
      },
      "outputs": [],
      "source": [
        "test_labels = test_everything[1]\n",
        "train_labels = train_everything[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hhr7p6POW2go"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.reshape((3228, 128, 128, 1))\n",
        "train_data = np.concatenate([train_data, train_data, train_data], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bQRJFhFW4r9"
      },
      "outputs": [],
      "source": [
        "test_data = test_data.reshape((807, 128, 128, 1))\n",
        "test_data = np.concatenate([test_data, test_data, test_data], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmCSGuxXC_V2"
      },
      "outputs": [],
      "source": [
        "conv_base = tf.keras.applications.DenseNet201(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        pooling='max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPemLcqGzUyN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oom1DbkvlZxe"
      },
      "outputs": [],
      "source": [
        "# input layer\n",
        "input_layer = tf.keras.Input(shape=(128, 128, 3))\n",
        "input_layer_aux = tf.keras.layers.Input(shape=(128, 128, 3))\n",
        "conv1_aux = conv_base(input_layer_aux)\n",
        "conv3_aux = tf.keras.layers.Flatten()(conv1_aux)\n",
        "\n",
        "# encode\n",
        "conv1 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(input_layer)\n",
        "conv1_2 = tf.keras.layers.BatchNormalization()(conv1)\n",
        "conv2 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv1_2)\n",
        "conv2_2 = tf.keras.layers.BatchNormalization()(conv2)\n",
        "conv4 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv2_2)\n",
        "conv3_2 = tf.keras.layers.BatchNormalization()(conv4)\n",
        "conv4 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv3_2)\n",
        "conv3_2 = tf.keras.layers.BatchNormalization()(conv4)\n",
        "conv4 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv3_2)\n",
        "conv3_2 = tf.keras.layers.BatchNormalization()(conv4)\n",
        "conv4 = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv3_2)\n",
        "\n",
        "conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
        "\n",
        "# decode\n",
        "deconv1 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(conv4)\n",
        "deconv2 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(deconv1)\n",
        "deconv4 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(deconv2)\n",
        "deconv4 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(deconv4)\n",
        "deconv4 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(deconv4)\n",
        "deconv4 = tf.keras.layers.Conv2DTranspose(32, kernel_size=(2,2))(deconv4)\n",
        "# output\n",
        "deconv_final = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(deconv4)\n",
        "conv = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv4)\n",
        "conv = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv)\n",
        "conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "conv = tf.keras.layers.MaxPool2D()(conv)\n",
        "\n",
        "conv = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv)\n",
        "conv = tf.keras.layers.Conv2D(32, kernel_size=(2,2))(conv)\n",
        "conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "conv = tf.keras.layers.MaxPool2D()(conv)\n",
        "\n",
        "aux_output = tf.keras.layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(conv)\n",
        "aux_output = tf.keras.layers.Flatten()(aux_output)\n",
        "\n",
        "# concatenate\n",
        "concat_layer = tf.keras.layers.Concatenate()([aux_output, conv3_aux])\n",
        "clf_dense_1 = tf.keras.layers.Dense(128, activation = \"relu\")(concat_layer)\n",
        "clf_dropout_1 = tf.keras.layers.Dropout(0.2)(clf_dense_1)\n",
        "clf_dense_2 = tf.keras.layers.Dense(64, activation = \"relu\")(clf_dropout_1)\n",
        "clf_dropout_2 = tf.keras.layers.Dropout(0.3)(clf_dense_2)\n",
        "clf_dense_3 = tf.keras.layers.Dense(32, activation = \"relu\")(clf_dropout_2)\n",
        "clf_dropout_3 = tf.keras.layers.Dropout(0.2)(clf_dense_3)\n",
        "aux_output_dense = tf.keras.layers.Dense(3, activation = \"softmax\")(clf_dropout_3)\n",
        "\n",
        "# final model\n",
        "final_model = tf.keras.models.Model(inputs = [input_layer, input_layer_aux], outputs = [deconv_final, aux_output_dense])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvUEYjKN7jrK"
      },
      "outputs": [],
      "source": [
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_dd6taqSHcU"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(final_model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5SkMLSSBv7R"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(0.0001)\n",
        "final_model.compile(\n",
        "    optimizer = opt, # \"Adam\"\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\", tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0])]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hKwRlsS9EddO"
      },
      "outputs": [],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  history = final_model.fit(\n",
        "      [train_data, train_data], [train_data[:, :, :, 0:1], train_labels], # rescale (aka /255.)\n",
        "      validation_data = ([test_data, test_data], [test_data[:, :, :, 0:1], test_labels]),\n",
        "      batch_size = 1,\n",
        "      epochs = 100\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cMI9m3lyRurA"
      },
      "outputs": [],
      "source": [
        "print(\"best train loss: \" + str(min(history.history['dense_3_loss'])) + \"\\n\" + \"best train acc: \" + str(max(history.history['dense_3_accuracy'])))\n",
        "print(\"best test loss: \" + str(min(history.history['val_dense_3_loss'])) + \"\\n\" + \"best test acc: \" + str(max(history.history['val_dense_3_accuracy'])))\n",
        "print(\"best conv test acc: \" + str(max(history.history['conv2d_6_accuracy'])) + \"\\n\" + \"best conv train acc: \" + str(max(history.history['val_conv2d_6_accuracy'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aZKQ4ycAFLIE"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "acc = history.history['dense_3_accuracy']\n",
        "val_acc = history.history['val_dense_3_accuracy']\n",
        "\n",
        "loss = history.history['dense_3_loss']\n",
        "val_loss = history.history['val_dense_3_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkSaucOpwrSOBlqhrMvni5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}